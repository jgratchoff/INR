\section{Literature review}
\label{relwork}
The creation of the HTTP/2 protocol has been discussed for many years. This section discusses the drawbacks of the previous version and presents the reasons why a new protocol should be moved to. The features that will improve the performance of the HTTP/2 protocol are also introduced. And finally the related work section will present the benchmarks that have been made for the SPDY and HTTP/2 protocol. Information has been derived from the HTTP/2 draft\cite{http2} and from Daniel Stenberg's paper explaining HTTP/2\cite{stenberg}. 

\subsection{HTTP/1.1 drawbacks}
The HTTP/1.1 protocol uses a client-server model where the client is most of the time a browser that is getting data from a server. Since the early beginning of the protocol, users had complained about the time that a page takes to load. In the early days one major reason for this problem was not due to the protocol but to the speed and the reliability of the Internet. However the web has changed and more and more users have a high speed and reliable connection to the Internet. This and the growth of clients on the web has led to the increase of web page size and the number of elements on a web page. HTTP/1.1 was not designed for this use as indeed it uses the TCP protocol inadequately by retrieving one element from a web page using one TCP connection. Thus it does not take full advantage of the TCP protocol. The current use of TCP in HTTP/1.1 protocol can introduce problems (e.g. head of line blocking,headers redundancy) that lead to a slower loading time. Loading time is also highly dependent on the Round Trip Time (RTT) and some efforts have been made on improving these aspects over the years by adding geographical redundancy. However the problem is still present for low cost organisations that are only able to develop servers in a single location. 
This latency directly affects the clients and can be critical for any website (e.g. users leaving the page as it takes too long to load). So over the years, web developers have tried to reduce this critical factor. In order to do so they have tried to adapt themselves to the protocol with workarounds that reduce the number of TCP connections. The best known workarounds are:
\begin{itemize}
\item Spriting: The act of creating an image containing many pictures destined to be present on the website and let the browsers display (via CSS or Javascript) the picture wanted by cropping/cutting out a single image.
\item Sharding: In order to overcome the problem of increasing TCP connections per domain, developers started to create several domains, holding different parts of the website. This decreases the page loading time by reducing the number of connections per domain, thus leading to a better performance of the HTTP/1.1 protocol. This method can also be used to allow more TCP sessions as each domain is bounded to a certain number.
\item Concatenation: In order to reduce the number of TCP connections, developers started to concatenate files (e.g. javascript) into one big file. 
\item Inlining: By embedding the data straight in the CSS in base64 format it avoids sending pictures and thus creating new TCP connections. 
\end{itemize}
All these workarounds were needed as the page loading time and the number of requests were increasing so much that the web was slowing down even though more and more people had access to a reliable connection. That is why the IETF created a working group named HTTPbis\cite{httpbis} that started working on a new protocol. Beforehand Google started working on a new protocol, called SPDY\cite{spdy}, that was aiming to face the problems from the HTTP/1.1 protocol. The HTTPbis group started working from a working concept of protocol in the name of SPDY/3 (draft). And this was the start of HTTP/2.
\newpage
\subsection{HTTP/2 improvements}
This section is subdivided into several parts describing the major improvements made over its predecessor HTTP/1.1 and emphasis on the reasons for moving to the new HTTP/2 protocol for large scale environments. 

\subsubsection{Binary format}
HTTP/1.1 is based on a text/ascii format which is an advantage for humans to read and thus to debug the protocol. It is described by Raymond as "easy for human beings to read, write, and edit without specialized tools"\cite{raymond}. However for computers such as clients and servers, ascii is not their mother tongue. Indeed computers use binary as a format for exchange. HTTP/2 uses this format.
"HTTP/2 also enables more efficient processing of messages through use of binary messages framing."\cite{http2} Binary is known to be much more efficient for binary structures. It is indeed hard to define the start and the end of a field in text based protocols. However with binary format it is much more natural. Binary will then improve the structure of the protocol and thus the efficiency of the protocol. In order to overcome the difficulty of debugging the binary protocol, tools such as curl\cite{curlhttp2} have added support for HTTP/2 and Wireshark have created extensions\cite{wiresharkhttp2} to decode the network streams.

\subsubsection{Multiplexing and priority}
The use of streams is a major enhancement of the HTTP/2 protocol. A stream is described in the specification as "an independent, bi-directional sequence of frames exchanged between the client and server within an HTTP/2 connection."\cite{http2} The stream identifier, present in the header format as an integer, will associate each frame belonging to the same stream. One HTTP/2 connection can contain several concurrently open streams, that can each be closed by the client or the server. Streams are multiplexed which can mean that they do not arrive in the same order as that in which they have been sent. It is the role of the client to put these streams back together in a correct order to process the data. 
Each stream has a priority that can be set by the client in the HEADERS frame that opens the stream. This priority can be changed to re-prioritize a specific stream. This can enable an endpoint to be allowed to express how it would prefer to retrieve data when managing multiple concurrent streams. A stream can also be dependent on other streams by setting the stream dependency parameter.

\subsubsection{Header compression}
One of the problems of HTTP/1.1 described earlier is that more and more elements are retrieved per web page. If multiple elements are similar in type and location the headers will closely resemble each other. This redundancy in the requests consumes bandwidth unnecessarily.\cite{hpack} Header compression comes as an appropriate  solution to this problem. Previously implemented in HTTPS and SPDY, the compression mechanism used were vulnerable to the BREACH\cite{breach} and CRIME\cite{crime} attacks. That is why the HTTPbis group has created a new compression format HPACK\cite{hpack}. It is used to represent efficiently HTTP header fields, to be used in HTTP/2. HPACK is described as "simple and inflexible."\cite{hpack} It eliminates redundant header fields and prevents security issues.

\subsubsection{Flow control}
The flow control is implemented in HTTP/2 by assigning an integer value to a window that will define how many octets of data the sender (server) is able to transmit. In that way the server is taking in consideration the buffering capacity of the receiver. This has enormous advantages as receivers on the web can be of different natures (e.g.Smartphones, laptop) with different connections. Flow control can either operate on the entire connection or on each individual stream. The default value is 65535 octets. In order to reassign this value the receiver (client) can send a SETTINGS frame with his flow control integer value.

\subsubsection{Server push}
HTTP/2 allows the server to send extra information with a requested information required by a client. This functionality allows the overall loading time to be increased by anticipating what the client will need before it asks for it. In that way the client will already possess the information when asking for it. This is called the server push mechanism. This mechanism is not required but can improve the user experience. The client must allow the server to do so. This allows the client to stay in control and indeed the client is able to terminate that pushed stream by sending a RST\_STREAM.

\subsection{Related work}
The new HTTP2 protocol has been based on the SPDY protocol developed mainly by Google. As shown by Google \cite{google2x}, the SPDY protocol meets its expectations by reducing the loading time of web pages by 55\%. Other people have tried to look into the protocol and one of the most interesting analyses has been made by Servy\cite{servy}. Servy evaluated the performance of the web servers implementing the SPDY protocol comparing it to HTTP/1.1 and HTTPS. The load testing tool used for this benchmark was the NeoLoad 4.1.2. Its results showed that the implementation of SPDY increases by a factor of 6 the number concurrent of users possible before errors start showing up in comparison to HTTP and HTTPS. 
A contradictory study showing some boundaries of implementing SPDY has been done by Podjarny\cite{podiatry}. He shows that most of the websites use different domains and as SPDY works on a per-domain basis it does not necessarily help it to be faster. Finally, Wang et al.\cite{wang} have investigated the performance of SPDY for the improvements of the protocol compared to HTTP/1.1. This study highlights the fact that SPDY is much faster since its benefits from the single TCP connection mechanism. However, they also mention that SPDY degrades under high packet loss compared to HTTP. 
Concerning the new standard HTTP/2 a few benchmarks have been performed by the creators of different client/server platforms. They reach the same conclusion for SPDY. \\
However, studies on comparisons between HTTP/2 (draft-ietf-httpbis-http2-14 \cite{h2c-14} ) and HTTP/1.1 with regards to concurrent clients and increasing amounts of requests in different geographical locations and different page sizes or the amount of elements a web page contains, have not yet been conducted.

\subsection{Conclusion}
To conclude, this section presented the reasons that have led to the design of a new version of the HTTP protocol. The TCP protocol was implemented in the HTTP protocol in the early days of the web however due to the evolution of the web, the protocol started lacking and the principal reason was that the use of the TCP protocol did not suit the web usage any more. HTTP/2 address these issues by exploiting in a better way the TCP protocol. It also creates new features that will redesign the way large infrastructure is implemented such as flow control, stream priority or server push. The new performances of the protocol have been tested by the designers of the implementation of the protocol but not by other parties. That is why this research has been conducted.